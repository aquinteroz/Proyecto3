{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de neumonía usando CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este *Notebook* se aborda la clasificación de la neumonía mediante CNN (red neuronal convolucional). Además, también se experimentará con valores de umbral.\n",
    "\n",
    "La neumonía es una enfermedad inflamatoria de los pulmones que afecta principalmente a los pequeños sacos de aire, conocidos como alvéolos. Por lo general, los síntomas incluyen una combinación de tos productiva o seca, dolor en el pecho, fiebre y dificultad para respirar.\n",
    "\n",
    "Obtenga más información en: <a href='https://www.who.int/news-room/fact-sheets/detail/pneumonia'>Organización Mundial de la Salud</a>\n",
    "\n",
    "<center><img src='https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Chest_X-ray_in_influenza_and_Haemophilus_influenzae_-_annotated.jpg/1200px-Chest_X-ray_in_influenza_and_Haemophilus_influenzae_-_annotated.jpg' alt='Pneumonia' height='800' width='300'> </center>\n",
    "<p>Fuente: Wikipedia</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de módulo y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "import pickle \n",
    "import os \n",
    "import numpy as np\n",
    "import cv2 \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesa las imágenes y redimensionalas al tamaño preferido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 200\n",
    "def get_training_data(data_dir):\n",
    "    dataX = [] \n",
    "    dataY = []\n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                dataX.append(resized_arr)\n",
    "                dataY.append(class_num)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = get_training_data('chest_xray/train')\n",
    "testX, testY = get_training_data('chest_xray/test')\n",
    "valX, valY = get_training_data('chest_xray/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnenumonia = 0 \n",
    "normal = 0 \n",
    "\n",
    "for j in trainY:\n",
    "    if j == 0:\n",
    "        pnenumonia+=1\n",
    "    else:\n",
    "        normal+=1\n",
    "        \n",
    "print('Pneumonia:', pnenumonia)\n",
    "print('Normal:', normal)\n",
    "print('Pneumonia - Normal:', pnenumonia-normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar imágenes de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trainX[4000], cmap='gray')\n",
    "print(labels[trainY[4000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos incorporando los datos de validación en los datos de entrenamiento porque no contienen suficientes ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for feature in trainX:\n",
    "    X.append(feature)\n",
    "    \n",
    "for label in trainY:\n",
    "    y.append(label)\n",
    "    \n",
    "for feature in testX:\n",
    "    X.append(feature)\n",
    "\n",
    "for label in testY:\n",
    "    y.append(label)\n",
    "    \n",
    "for feature in valX:\n",
    "    X.append(feature)\n",
    "\n",
    "for label in valY:\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, img_size, img_size, 1)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (Red neuronal convolucional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='cnn.PNG' alt='CNN'> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X_train.shape[1:], padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid')) # cambiar a 'lineal' para regresión\n",
    "\n",
    "early_stop = EarlyStopping(patience=3, monitor='val_loss')\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=15, epochs=5, validation_split=0.20, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando nuestro progreso en el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plt.plot(history.epoch, history.history['acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.plot(history.epoch, history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.plot(history.epoch, history.history['val_acc'])\n",
    "plt.title('Model Validation Accuracy')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.plot(history.epoch, history.history['val_loss'])\n",
    "plt.title('Model Validation Loss')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar los datos para *precision* vs. *recall* y ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_train)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, pred)\n",
    "fpr, tpr, thresholds2 = roc_curve(y_train, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], 'b--')\n",
    "    plt.plot(thresholds, recalls[:-1], 'g-')\n",
    "    plt.title('Precision vs. Recall')\n",
    "    plt.xlabel('Thresholds')\n",
    "    plt.legend(['Precision', 'Recall'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(fpr, tpr):\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.title('FPR (False Positive rate) vs TPR (True Positive Rate)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.show()\n",
    "    \n",
    "plot_precision_recall(precisions, recalls, thresholds)\n",
    "plot_roc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establecimiento de umbrales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos que los resultados sean precisos sin sacrificar demasiado el *recall*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = []\n",
    "threshold = thresholds[np.argmax(precisions >= 0.95)]\n",
    "for i in predictions:\n",
    "    if i >= threshold:\n",
    "        binary_predictions.append(1)\n",
    "    else:\n",
    "        binary_predictions.append(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy on testing set:', accuracy_score(binary_predictions, y_test))\n",
    "print('Precision on testing set:', precision_score(binary_predictions, y_test))\n",
    "print('Recall on testing set:', recall_score(binary_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico de la matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se explica cómo interpretarla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='conf_mat.PNG' alt='Matriz de confusión'> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(binary_predictions, y_test)\n",
    "plt.figure(figsize=(16, 9))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(matrix, annot=True, ax = ax)\n",
    "\n",
    "# etiquetas, título y marcas\n",
    "ax.set_xlabel('Predicted Labels', size=20)\n",
    "ax.set_ylabel('True Labels', size=20)\n",
    "ax.set_title('Confusion Matrix', size=20) \n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train.reshape(-1, img_size, img_size)[i], cmap='gray')\n",
    "    if(binary_predictions[i]==y_test[i]):\n",
    "        plt.xlabel(labels[binary_predictions[i]], color='blue')\n",
    "    else:\n",
    "        plt.xlabel(labels[binary_predictions[i]], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.save('pneumonia_detection_ai_version_2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
